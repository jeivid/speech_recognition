{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(file_path, chunk_length_ms=30000, overlap_ms=1000):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    end = chunk_length_ms\n",
    "    while start < len(audio):\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_length_ms - overlap_ms\n",
    "        end = start + chunk_length_ms\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunks(chunks, model_name='base'):\n",
    "    model = whisper.load_model(model_name)\n",
    "    transcriptions = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "        chunk.export(chunk_file, format=\"wav\")\n",
    "        result = model.transcribe(chunk_file)\n",
    "        transcriptions.append(result[\"text\"])\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_temp_files(chunks):\n",
    "    for i in range(len(chunks)):\n",
    "        os.remove(f\"temp_chunk_{i}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks = split_audio(\"Akhundzade3.mp3\")\n",
    "for i in range(0, len(audio_chunks), 4):\n",
    "    transcriptions = transcribe_chunks(audio_chunks[i:i+4])\n",
    "    partial_transcription = ' '.join(transcriptions)\n",
    "    print(f\"Raw partial transcription: {partial_transcription}\")\n",
    "    clean_up_temp_files(audio_chunks)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a kind assistant, skilled in transforming poorly written farsi into proper formal language, without mistakes and misunderstandings. You avoid adding comments, you just rewrite the user input and do not add any comment.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{partial_transcription}\"}\n",
    "        ]\n",
    "    )\n",
    "    processed_partial_transcription = completion.choices[0].message.content\n",
    "    print(f\"Processed partial transcription: {processed_partial_transcription}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
